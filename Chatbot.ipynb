{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hPSJIkJOOUt",
        "outputId": "22e95103-36e1-428c-9289-89c37cb21764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import math\n",
        "import json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_name = \"movie-corpus\"\n",
        "corpus = os.path.join(\"/content/drive/My Drive/\", corpus_name)\n",
        "\n",
        "def printLines(file, n=10):\n",
        "    with open(file, 'rb') as datafile:\n",
        "        lines = datafile.readlines()\n",
        "    for line in lines[:n]:\n",
        "        print(line)\n",
        "\n",
        "printLines(os.path.join(corpus, \"utterances.jsonl\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v94_6fdFSY9-",
        "outputId": "74454539-9cf2-4ef9-9f78-251ea1926077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'{\"id\": \"L1045\", \"conversation_id\": \"L1044\", \"text\": \"They do not!\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"not\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L1044\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L1044\", \"conversation_id\": \"L1044\", \"text\": \"They do to!\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"dobj\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L985\", \"conversation_id\": \"L984\", \"text\": \"I hope so.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"hope\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"so\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 1, \"dn\": []}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L984\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L984\", \"conversation_id\": \"L984\", \"text\": \"She okay?\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"She\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"okay\", \"tag\": \"RB\", \"dep\": \"ROOT\", \"dn\": [0, 2]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L925\", \"conversation_id\": \"L924\", \"text\": \"Let\\'s go.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Let\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [2, 3]}, {\"tok\": \"\\'s\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"go\", \"tag\": \"VB\", \"dep\": \"ccomp\", \"up\": 0, \"dn\": [1]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L924\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L924\", \"conversation_id\": \"L924\", \"text\": \"Wow\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Wow\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L872\", \"conversation_id\": \"L870\", \"text\": \"Okay -- you\\'re gonna need to learn how to lie.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 4, \"toks\": [{\"tok\": \"Okay\", \"tag\": \"UH\", \"dep\": \"intj\", \"up\": 4, \"dn\": []}, {\"tok\": \"--\", \"tag\": \":\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"\\'re\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"gon\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 6, 12]}, {\"tok\": \"na\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 6, \"dn\": []}, {\"tok\": \"need\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 8]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 8, \"dn\": []}, {\"tok\": \"learn\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 6, \"dn\": [7, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 11, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 11, \"dn\": []}, {\"tok\": \"lie\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 8, \"dn\": [9, 10]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": \"L871\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L871\", \"conversation_id\": \"L870\", \"text\": \"No\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"No\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": \"L870\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L870\", \"conversation_id\": \"L870\", \"text\": \"I\\'m kidding.  You know how sometimes you just become this \\\\\"persona\\\\\"?  And you don\\'t know how to quit?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 2, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"\\'m\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 2, \"dn\": []}, {\"tok\": \"kidding\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 3]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 2, \"dn\": [4]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 3, \"dn\": []}]}, {\"rt\": 1, \"toks\": [{\"tok\": \"You\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 6, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 3, \"dn\": []}, {\"tok\": \"sometimes\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": [2]}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 6, \"dn\": []}, {\"tok\": \"just\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": []}, {\"tok\": \"become\", \"tag\": \"VBP\", \"dep\": \"ccomp\", \"up\": 1, \"dn\": [3, 4, 5, 9]}, {\"tok\": \"this\", \"tag\": \"DT\", \"dep\": \"det\", \"up\": 9, \"dn\": []}, {\"tok\": \"\\\\\"\", \"tag\": \"``\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"persona\", \"tag\": \"NN\", \"dep\": \"attr\", \"up\": 6, \"dn\": [7, 8, 10]}, {\"tok\": \"\\\\\"\", \"tag\": \"\\'\\'\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": [12]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 11, \"dn\": []}]}, {\"rt\": 4, \"toks\": [{\"tok\": \"And\", \"tag\": \"CC\", \"dep\": \"cc\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"n\\'t\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 4, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 7, 8]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 7, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 7, \"dn\": []}, {\"tok\": \"quit\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 6]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L869\", \"conversation_id\": \"L866\", \"text\": \"Like my fear of wearing pastels?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Like\", \"tag\": \"IN\", \"dep\": \"ROOT\", \"dn\": [2, 6]}, {\"tok\": \"my\", \"tag\": \"PRP$\", \"dep\": \"poss\", \"up\": 2, \"dn\": []}, {\"tok\": \"fear\", \"tag\": \"NN\", \"dep\": \"pobj\", \"up\": 0, \"dn\": [1, 3]}, {\"tok\": \"of\", \"tag\": \"IN\", \"dep\": \"prep\", \"up\": 2, \"dn\": [4]}, {\"tok\": \"wearing\", \"tag\": \"VBG\", \"dep\": \"pcomp\", \"up\": 3, \"dn\": [5]}, {\"tok\": \"pastels\", \"tag\": \"NNS\", \"dep\": \"dobj\", \"up\": 4, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L868\", \"timestamp\": null, \"vectors\": []}\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loadLinesAndConversations(fileName):\n",
        "  lines = {}\n",
        "  conversations = {}\n",
        "  with open(fileName, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "      lineJson = json.loads(line)\n",
        "      lineObj = {}\n",
        "      lineObj[\"LineID\"] = lineJson[\"id\"]\n",
        "      lineObj[\"characterID\"] = lineJson[\"speaker\"]\n",
        "      lineObj[\"text\"] = lineJson[\"text\"]\n",
        "      lines[lineObj[\"LineID\"]] = lineObj\n",
        "\n",
        "      if lineJson[\"conversation_id\"] not in conversations:\n",
        "        convObj = {}\n",
        "        convObj[\"conversationID\"] = lineJson[\"conversation_id\"]\n",
        "        convObj[\"movieID\"] = lineJson[\"meta\"][\"movie_id\"]\n",
        "        convObj[\"lines\"] = [lineObj]\n",
        "      else:\n",
        "          convObj= conversations[lineJson[\"conversation_id\"]]\n",
        "          convObj[\"lines\"].insert(0, lineObj)\n",
        "      conversations[convObj[\"conversationID\"]] = convObj\n",
        "    return lines, conversations\n",
        "\n",
        "def extractSentencePairs(conversations):\n",
        "    qa_pairs = []\n",
        "    for conversation in conversations.values():\n",
        "      for i in range(len(conversation[\"lines\"]) - 1):\n",
        "        inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
        "        targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
        "        if inputLine and targetLine:\n",
        "          qa_pairs.append([inputLine, targetLine])\n",
        "    return qa_pairs\n",
        "\n"
      ],
      "metadata": {
        "id": "yjM7UtvnWkFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
        "\n",
        "delimiter = '\\t'\n",
        "\n",
        "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
        "\n",
        "lines = {}\n",
        "conversations = {}\n",
        "\n",
        "print(\"\\nProcessing corpus into lines and conversations...\")\n",
        "lines, conversations = loadLinesAndConversations(os.path.join(corpus, \"utterances.jsonl\"))\n",
        "\n",
        "print(\"\\nWriting newly formatted file...\")\n",
        "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
        "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
        "    for pair in extractSentencePairs(conversations):\n",
        "        writer.writerow(pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M1V-vJSYb71",
        "outputId": "6b40feb6-741f-4074-c14e-ef3f59d4d2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing corpus into lines and conversations...\n",
            "\n",
            "Writing newly formatted file...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSample lines from file:\")\n",
        "printLines(datafile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqNhE1bSaVTf",
        "outputId": "33d2f63d-63d1-49de-c6e1-590bcae4b94b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample lines from file:\n",
            "b'They do to!\\tThey do not!\\n'\n",
            "b'She okay?\\tI hope so.\\n'\n",
            "b\"Wow\\tLet's go.\\n\"\n",
            "b'\"I\\'m kidding.  You know how sometimes you just become this \"\"persona\"\"?  And you don\\'t know how to quit?\"\\tNo\\n'\n",
            "b\"No\\tOkay -- you're gonna need to learn how to lie.\\n\"\n",
            "b\"I figured you'd get to the good stuff eventually.\\tWhat good stuff?\\n\"\n",
            "b'What good stuff?\\t\"The \"\"real you\"\".\"\\n'\n",
            "b'\"The \"\"real you\"\".\"\\tLike my fear of wearing pastels?\\n'\n",
            "b'do you listen to this crap?\\tWhat crap?\\n'\n",
            "b\"What crap?\\tMe.  This endless ...blonde babble. I'm like, boring myself.\\n\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_token = 0\n",
        "SOS_token = 1\n",
        "EOS_token = 2\n",
        "\n",
        "class Voc:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.trimmed = False\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "    self.num_words = 3\n",
        "\n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(\" \"):\n",
        "      self.addWord(word)\n",
        "\n",
        "  def addWord(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.num_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.num_words] = word\n",
        "      self.num_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1\n",
        "\n",
        "  def trim(self, min_count):\n",
        "    if self.trimmed:\n",
        "      return\n",
        "    self.trimmed = True\n",
        "\n",
        "    keep_words = []\n",
        "\n",
        "    for k, v in self.word2count.items():\n",
        "      if v >= min_count:\n",
        "        keep_words.append(k)\n",
        "\n",
        "    print(\"keep_words {} / {} = {:.4f}\".format(len(keep_words),\n",
        "                                               len(self.word2index),\n",
        "                                               len(keep_words) / len(self.word2index)))\n",
        "\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "    self.num_words = 3\n",
        "\n",
        "    for word in keep_words:\n",
        "      self.addWord(word)"
      ],
      "metadata": {
        "id": "tClIRN6maexT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "  return \"\".join(\n",
        "      c for c in unicodedata.normalize(\"NFD\", s)\n",
        "      if unicodedata.category(c) != \"Mn\"\n",
        "  )\n",
        "\n",
        "def normalizeString(s):\n",
        "  s = unicodeToAscii(s.lower().strip())\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "  s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "  return s\n",
        "\n",
        "def readVocs(datafile, corpus_name):\n",
        "  print(\"Reading lines...\")\n",
        "  lines = open(datafile, encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
        "  pairs = [[normalizeString(s) for s in l.split(\"\\t\")] for l in lines]\n",
        "  voc = Voc(corpus_name)\n",
        "  return voc, pairs\n",
        "\n",
        "def filterPair(p):\n",
        "  return len(p[0].split(\" \")) < MAX_LENGTH and len(p[1].split(\" \")) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "  return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "def loadPreparedData(corpus, corpus_name, datafile, save_dir):\n",
        "  print(\"Start preparing training data...\")\n",
        "  voc, pairs = readVocs(datafile, corpus_name)\n",
        "  print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
        "  pairs = filterPairs(pairs)\n",
        "  print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
        "  print(\"Counting words...\")\n",
        "  for pair in pairs:\n",
        "    voc.addSentence(pair[0])\n",
        "    voc.addSentence(pair[1])\n",
        "  print(\"Counted words:\", voc.num_words)\n",
        "  return voc, pairs"
      ],
      "metadata": {
        "id": "49yHTWbOeEiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = os.path.join(\"data\", \"save\")\n",
        "voc, pairs = loadPreparedData(corpus, corpus_name, datafile, save_dir)\n",
        "# Print some pairs to validate\n",
        "print(\"\\npairs:\")\n",
        "for pair in pairs[:10]:\n",
        "  print(pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQlj8TCkgXjd",
        "outputId": "d82413ae-9395-4897-9c96-d3b1c3b8d67c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start preparing training data...\n",
            "Reading lines...\n",
            "Read 221282 sentence pairs\n",
            "Trimmed to 64313 sentence pairs\n",
            "Counting words...\n",
            "Counted words: 18082\n",
            "\n",
            "pairs:\n",
            "['they do to !', 'they do not !']\n",
            "['she okay ?', 'i hope so .']\n",
            "['wow', 'let s go .']\n",
            "['what good stuff ?', 'the real you .']\n",
            "['the real you .', 'like my fear of wearing pastels ?']\n",
            "['do you listen to this crap ?', 'what crap ?']\n",
            "['well no . . .', 'then that s all you had to say .']\n",
            "['then that s all you had to say .', 'but']\n",
            "['but', 'you always been this selfish ?']\n",
            "['have fun tonight ?', 'tons']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_COUNT = 3\n",
        "\n",
        "def trimRareWords(voc, pairs, MIN_COUNT):\n",
        "  voc.trim(MIN_COUNT)\n",
        "  keep_pairs = []\n",
        "  for pair in pairs:\n",
        "    input_sentence = pair[0]\n",
        "    output_sentence = pair[1]\n",
        "    keep_input = True\n",
        "    keep_output = True\n",
        "    for word in input_sentence.split(\" \"):\n",
        "      if word not in voc.word2index:\n",
        "        keep_input = False\n",
        "        break\n",
        "    for word in output_sentence.split(\" \"):\n",
        "      if word not in voc.word2index:\n",
        "        keep_output = False\n",
        "        break\n",
        "    if keep_input and keep_output:\n",
        "      keep_pairs.append(pair)\n",
        "  print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs),\n",
        "                                                              len(keep_pairs),\n",
        "                                                              len(keep_pairs) / len(pairs)))\n",
        "  return keep_pairs\n",
        "\n",
        "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEvcT5Kogyqy",
        "outputId": "4a62f986-a517-4536-e35e-7813c51a8edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keep_words 7833 / 18079 = 0.4333\n",
            "Trimmed from 64313 pairs to 53131, 0.8261 of total\n"
          ]
        }
      ]
    }
  ]
}